{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"titanic/train.csv\")\n",
    "vali_df = pd.read_csv(\"titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare\n",
       "0       3    male  22.0      1      0   7.2500\n",
       "1       1  female  38.0      1      0  71.2833\n",
       "2       3  female  26.0      0      0   7.9250\n",
       "3       1  female  35.0      1      0  53.1000\n",
       "4       3    male  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare\n",
       "count  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean     2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std      0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min      1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%      1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%      3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%      3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max      3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vali_df[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df.iloc[:,[2,4,5,6,7,9]].values\n",
    "x_vali = vali_df.iloc[:,[1,3,4,5,6,8]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imputer = imputer.fit(x[:,2:3])\n",
    "x[:,2:3] = imputer.transform(x[:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_x_vali = Imputer(missing_values=\"NaN\",strategy=\"median\",axis=0)\n",
    "imputer_x_vali = imputer_x_vali.fit(x_vali[:,[2,5]])\n",
    "x_vali[:,[2,5]] = imputer_x_vali.transform(x_vali[:,[2,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_vali[[266,372],5:6] = 14.454200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_x = LabelEncoder()\n",
    "x[:,1] = labelencoder_x.fit_transform(x[:,1])\n",
    "labelencoder_v = LabelEncoder()\n",
    "x_vali[:,1] = labelencoder_v.fit_transform(x_vali[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,418):\n",
    "    if x_vali[i,5:6] == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "onehotencoder_x = OneHotEncoder(categorical_features = [1])\n",
    "x = onehotencoder_x.fit_transform(x).toarray()\n",
    "\n",
    "\n",
    "onehotencoder_v = OneHotEncoder(categorical_features = [1])\n",
    "x_vali = onehotencoder_v.fit_transform(x_vali).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  1.  ,  3.  , 22.  ,  1.  ,  0.  ,  7.25])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 7), (179, 7), (712,), (179,))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=87)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standarscaler_x = StandardScaler()\n",
    "x_train = standarscaler_x.fit_transform(x_train)\n",
    "x_test = standarscaler_x.transform(x_test)\n",
    "standarscaler_x_vali = StandardScaler()\n",
    "x_vali = standarscaler_x_vali.fit_transform(x_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=87, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=87)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=87, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf',random_state=87)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=87, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=87)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "712/712 [==============================] - 2s 3ms/step - loss: 0.6909 - acc: 0.5871\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 646us/step - loss: 0.6779 - acc: 0.6152\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 399us/step - loss: 0.6395 - acc: 0.6685\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 414us/step - loss: 0.5789 - acc: 0.7865\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 397us/step - loss: 0.5281 - acc: 0.7767\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 317us/step - loss: 0.4996 - acc: 0.7795\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 353us/step - loss: 0.4840 - acc: 0.7795\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 277us/step - loss: 0.4753 - acc: 0.7795\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 235us/step - loss: 0.4692 - acc: 0.7795\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 219us/step - loss: 0.4655 - acc: 0.7809\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 199us/step - loss: 0.4626 - acc: 0.7865\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 181us/step - loss: 0.4602 - acc: 0.7907\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 233us/step - loss: 0.4586 - acc: 0.7921\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4566 - acc: 0.7978\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 209us/step - loss: 0.4555 - acc: 0.7978\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4537 - acc: 0.7963\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4527 - acc: 0.7949\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4513 - acc: 0.7978\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4503 - acc: 0.7992\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4487 - acc: 0.7978\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 167us/step - loss: 0.4473 - acc: 0.8006\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 197us/step - loss: 0.4463 - acc: 0.7992\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4453 - acc: 0.7992\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4445 - acc: 0.8006\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4436 - acc: 0.8006\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4429 - acc: 0.8006\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.4417 - acc: 0.7992\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 194us/step - loss: 0.4412 - acc: 0.8020\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 178us/step - loss: 0.4399 - acc: 0.7978\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 230us/step - loss: 0.4389 - acc: 0.8006\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 271us/step - loss: 0.4385 - acc: 0.8048\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 329us/step - loss: 0.4372 - acc: 0.8006\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 226us/step - loss: 0.4363 - acc: 0.8034\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 280us/step - loss: 0.4362 - acc: 0.8062\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 396us/step - loss: 0.4350 - acc: 0.7992\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 288us/step - loss: 0.4352 - acc: 0.8076\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 249us/step - loss: 0.4333 - acc: 0.8048\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4322 - acc: 0.8006\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.4318 - acc: 0.8048\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4311 - acc: 0.8062\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4305 - acc: 0.8034\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 229us/step - loss: 0.4296 - acc: 0.8020\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 216us/step - loss: 0.4293 - acc: 0.8132\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 235us/step - loss: 0.4281 - acc: 0.8076\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 215us/step - loss: 0.4272 - acc: 0.8062\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4264 - acc: 0.8118\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.4266 - acc: 0.8020\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4259 - acc: 0.8104\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4263 - acc: 0.8118\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.4252 - acc: 0.8146\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 197us/step - loss: 0.4254 - acc: 0.8076\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 184us/step - loss: 0.4244 - acc: 0.8146\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4241 - acc: 0.8132\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4240 - acc: 0.8160\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4235 - acc: 0.8174\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4226 - acc: 0.8216\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 174us/step - loss: 0.4229 - acc: 0.8160\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 236us/step - loss: 0.4222 - acc: 0.8174\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.4221 - acc: 0.8202\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.4217 - acc: 0.8202\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4220 - acc: 0.8160\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.4211 - acc: 0.8230\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4211 - acc: 0.8244\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4210 - acc: 0.8230\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 232us/step - loss: 0.4203 - acc: 0.8230\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 191us/step - loss: 0.4209 - acc: 0.8216\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4205 - acc: 0.8202\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4196 - acc: 0.8174\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.4198 - acc: 0.8202\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4194 - acc: 0.8202\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.4189 - acc: 0.8216\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4186 - acc: 0.8202\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4188 - acc: 0.8230\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4185 - acc: 0.8202\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4186 - acc: 0.8188\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4184 - acc: 0.8216\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.4183 - acc: 0.8146\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4183 - acc: 0.8230\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4190 - acc: 0.8146\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4183 - acc: 0.8202\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 232us/step - loss: 0.4177 - acc: 0.8216\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4177 - acc: 0.8230\n",
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 211us/step - loss: 0.4177 - acc: 0.8230\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.4179 - acc: 0.8202\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.4176 - acc: 0.8216\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 190us/step - loss: 0.4174 - acc: 0.8202\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 213us/step - loss: 0.4165 - acc: 0.8188\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 190us/step - loss: 0.4165 - acc: 0.8202\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 201us/step - loss: 0.4161 - acc: 0.8230\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 258us/step - loss: 0.4163 - acc: 0.8188\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.4160 - acc: 0.8230\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.4160 - acc: 0.8188\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 204us/step - loss: 0.4161 - acc: 0.8188\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 173us/step - loss: 0.4150 - acc: 0.8216\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.4156 - acc: 0.8258\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.4152 - acc: 0.8216\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 284us/step - loss: 0.4149 - acc: 0.8244\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 496us/step - loss: 0.4147 - acc: 0.8244\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 320us/step - loss: 0.4149 - acc: 0.8216\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 499us/step - loss: 0.4155 - acc: 0.8174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xeb070f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=4,kernel_initializer=\"uniform\",activation=\"relu\",input_dim=7))\n",
    "model.add(Dense(units=4,kernel_initializer=\"uniform\",activation=\"relu\"))\n",
    "model.add(Dense(units=1,kernel_initializer=\"uniform\",activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(x_train,y_train,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_model = round(model.score(x_test, y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.45"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 20],\n",
       "       [15, 53]], dtype=int64)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(98+51)/179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vali = model.predict(x_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_vali)\n",
    "df.to_csv(\"file_path1.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vali_id = vali_df.iloc[:,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"PassengerId\" : x_vali_id, \"Survived\" : y_vali})\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_vali_id = vali_df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 892,  893,  894,  895,  896,  897,  898,  899,  900,  901,  902,\n",
       "        903,  904,  905,  906,  907,  908,  909,  910,  911,  912,  913,\n",
       "        914,  915,  916,  917,  918,  919,  920,  921,  922,  923,  924,\n",
       "        925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
       "        936,  937,  938,  939,  940,  941,  942,  943,  944,  945,  946,\n",
       "        947,  948,  949,  950,  951,  952,  953,  954,  955,  956,  957,\n",
       "        958,  959,  960,  961,  962,  963,  964,  965,  966,  967,  968,\n",
       "        969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
       "        980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,\n",
       "        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001,\n",
       "       1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012,\n",
       "       1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023,\n",
       "       1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034,\n",
       "       1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045,\n",
       "       1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056,\n",
       "       1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067,\n",
       "       1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078,\n",
       "       1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089,\n",
       "       1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100,\n",
       "       1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111,\n",
       "       1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122,\n",
       "       1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133,\n",
       "       1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144,\n",
       "       1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155,\n",
       "       1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166,\n",
       "       1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177,\n",
       "       1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188,\n",
       "       1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,\n",
       "       1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210,\n",
       "       1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221,\n",
       "       1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232,\n",
       "       1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243,\n",
       "       1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254,\n",
       "       1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265,\n",
       "       1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276,\n",
       "       1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287,\n",
       "       1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298,\n",
       "       1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vali_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
